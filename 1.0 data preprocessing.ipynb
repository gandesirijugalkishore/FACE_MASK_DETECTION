{"cells":[{"cell_type":"markdown","metadata":{"id":"WBr8WoNyeIRn"},"source":["# Project Overview\n","![Architecture_1.png](attachment:Architecture_1.png)"]},{"cell_type":"markdown","metadata":{"id":"K8mIOzUieIRr"},"source":["# The Dataset\n","\n","The dataset consisted of 1376 images, 690 face images with masks and 686 without masks. The original dataset is prepared by [Prajna Bhandary](https://www.linkedin.com/in/prajna-bhandary-0b03a416a/) and available at [Github](https://github.com/prajnasb/observations/tree/master/experiements/data)\n","\n","![dataset.png](attachment:dataset.png)"]},{"cell_type":"markdown","metadata":{"id":"aIDtWO4PeIRs"},"source":["# Data Preprocessing\n","![pre.png](attachment:pre.png)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"66tRsu_YeIRt","executionInfo":{"status":"error","timestamp":1659593385839,"user_tz":300,"elapsed":699,"user":{"displayName":"Jugal Kishore","userId":"09710670921291355218"}},"outputId":"90571624-e6af-4547-b013-b4457ff33e33","colab":{"base_uri":"https://localhost:8080/","height":235}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-bac048eab912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset'"]}],"source":["import cv2,os\n","\n","data_path='dataset'\n","categories=os.listdir(data_path)\n","labels=[i for i in range(len(categories))]\n","\n","label_dict=dict(zip(categories,labels))\n","\n","print(label_dict)\n","print(categories)\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6W0l6nH9eIRv"},"outputs":[],"source":["img_size=100\n","data=[]\n","target=[]\n","\n","\n","for category in categories:\n","    folder_path=os.path.join(data_path,category)\n","    img_names=os.listdir(folder_path)\n","        \n","    for img_name in img_names:\n","        img_path=os.path.join(folder_path,img_name)\n","        img=cv2.imread(img_path)\n","\n","        try:\n","            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n","            #Coverting the image into gray scale\n","            resized=cv2.resize(gray,(img_size,img_size))\n","            #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset\n","            data.append(resized)\n","            target.append(label_dict[category])\n","            #appending the image and the label(categorized) into the list (dataset)\n","\n","        except Exception as e:\n","            print('Exception:',e)\n","            #if any exception rasied, the exception will be printed here. And pass to the next image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9Gc0umUeIRw"},"outputs":[],"source":["import numpy as np\n","\n","data=np.array(data)/255.0\n","data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n","target=np.array(target)\n","\n","from keras.utils import np_utils\n","\n","new_target=np_utils.to_categorical(target)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vwJ72U-veIRw"},"outputs":[],"source":["np.save('data',data)\n","np.save('target',new_target)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"1.0 data preprocessing.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}